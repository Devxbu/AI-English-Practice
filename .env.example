# Required
GROQ_API_KEY=
GOOGLE_APPLICATION_CREDENTIALS= # absolute path to your GCP service account JSON

# Audio backends
RECORDER=auto                  # auto|pvrecorder|lpcm16|file
PLAYER=default
DEVICE_INDEX=0                 # input device index (optional)
SESSION_DIR=sessions
DEMO=false                     # true|false
DEMO_SOURCE_WAV=               # used when RECORDER=file
NO_OVERLAP=false               # true to wait for playback before next recording

# AI provider
AI_PROVIDER=groq               # groq (OpenAI can be added later)

# Learning / UX features
SCENARIO=                      # coffee-shop|job-interview|travel|...
LEVEL=                         # beginner|intermediate|advanced
CORRECTIONS=off                # end-of-turn|inline|off
PRONUNCIATION_FEEDBACK=false   # true|false
EXPORT_VOCAB=                  # csv| (empty to disable)
LISTENING=false                # true|false
TOPIC=
MINUTES=2
CONTINUE=false                 # true|false (load last session defaults)

# Emotion-aware TTS (applies to both providers where possible)
EMOTION=                       # happy|sad|excited|calm (used if EMOTION_MODE=manual)
EMOTION_MODE=auto              # auto|manual

# TTS provider selection
TTS_PROVIDER=google            # google|piper

# Piper (free, local TTS)
PIPER_MODEL=                   # absolute path to .onnx model
PIPER_SPEAKER=0                # integer (if model is multi-speaker)
PIPER_LENGTH=1.0               # >1 slower, <1 faster
PIPER_NOISE=0.6                # expressiveness
PIPER_NOISE_W=0.8              # pronunciation/variation

# Google TTS A/B tuning
GOOGLE_VOICE=en-US-Neural2-F   # e.g., en-US-Neural2-J / en-US-Wavenet-F
GOOGLE_RATE=1.05               # speakingRate
GOOGLE_PITCH=-2.0              # semitones (e.g., 0, -2, +2)